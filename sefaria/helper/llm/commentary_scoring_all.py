#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Run LLM-based commentary scoring for all "Quoting Commentary" links in the DB.

This script:
- Scans db.links for links where exactly one side is a Commentary ref
  and the other side is a non-Commentary ref (i.e., quoting-style).
- Gathers unique commentary *segment* refs (e.g., "Ramban on Genesis 1:1:3").
- Calls generate_and_save_commentary_scoring(comm_ref) once per unique commentary ref.
- Skips commentary refs that already have any link with `relevance_score` unless --force-update.

Usage:
    python run_commentary_scoring_all.py
    python run_commentary_scoring_all.py --force-update
    python run_commentary_scoring_all.py --limit 1000 --dry-run

You can also import the `run_for_all_quoting_commentaries()` function in notebooks.
"""

import time
import argparse
from typing import Optional, Set

from sefaria.helper.llm.tasks.commentary_scoring import generate_and_save_commentary_scoring
from sefaria.model import library
from sefaria.system.database import db
from sefaria.system.exceptions import InputError
from commentary_scoring_tools import parse_link_for_base

# Ensure title maps are loaded (Ref parsing relies on this in some envs)
library.build_text_titles_json()


def _any_link_for_comm_has_score(comm_ref: str) -> bool:
    """
    Quick check: does ANY link that includes this commentary ref already have a relevance_score?
    Good enough to skip rescoring unless forced.
    """
    # Find any doc where this comm_ref appears in 'refs' and has a numeric or present relevance_score
    doc = db.links.find_one(
        {"refs": {"$in": [comm_ref]}, "relevance_score": {"$exists": True}},
        projection={"_id": 1},
    )
    return doc is not None


def iter_all_quoting_commentary_refs(limit: Optional[int] = None) -> Set[str]:
    """
    Walk the entire links collection and return a set of unique commentary refs that appear
    in "quoting-style" links (Commentary â†” non-Commentary).
    """
    comm_refs: Set[str] = set()
    seen = 0
    matched = 0

    # A light pre-filter can help performance. Many quoting links are generated by quotation finders
    # and often have types like "quotation" or "quotation_auto", but we don't rely on that. We still
    # parse both sides to be safe.
    cursor = db.links.find(
        {},  # full scan; add a projection to reduce payload
        projection={"refs": 1, "type": 1},
        no_cursor_timeout=True,
        batch_size=5000,
    )

    try:
        for link in cursor:
            seen += 1
            parsed = parse_link_for_base(link)
            if not parsed:
                continue
            comm_ref, _base_ref = parsed
            matched += 1
            comm_refs.add(comm_ref)

            if limit and len(comm_refs) >= limit:
                break

            # (Optional) occasional heartbeat
            if matched % 10000 == 0:
                print(f"[scan] seen={seen:,} matched={matched:,} unique_comms={len(comm_refs):,}")

    finally:
        cursor.close()

    print(f"[scan] DONE. scanned={seen:,}, quoting_links={matched:,}, unique_commentary_refs={len(comm_refs):,}")
    return comm_refs


def run_for_all_quoting_commentaries(force_update: bool = False,
                                     limit: Optional[int] = None,
                                     dry_run: bool = False,
                                     sleep_sec: float = 0.0) -> int:
    """
    Run generate_and_save_commentary_scoring() for every unique commentary ref we find in quoting links.
    Returns the count of commentary refs processed.
    """
    comm_refs = iter_all_quoting_commentary_refs(limit=limit)
    processed = 0
    skipped = 0
    errors = 0

    for i, comm_ref in enumerate(sorted(comm_refs)):
        # Skip if any existing relevance_score is present unless forced
        if not force_update and _any_link_for_comm_has_score(comm_ref):
            skipped += 1
            continue

        print(f"[{i+1}/{len(comm_refs)}] scoring: {comm_ref} (force_update={force_update})")
        if dry_run:
            processed += 1
            continue

        try:
            # This call should compute & persist scores on the relevant link(s) for this commentary ref
            generate_and_save_commentary_scoring(comm_ref)
            processed += 1
        except (InputError, Exception) as e:
            errors += 1
            print(f"[ERROR] {comm_ref}: {e}")

        if sleep_sec > 0:
            time.sleep(sleep_sec)

    print(f"[result] processed={processed:,} skipped={skipped:,} errors={errors:,} (total candidates={len(comm_refs):,})")
    return processed


def main(argv=None) -> int:
    p = argparse.ArgumentParser(description="Run commentary_scoring for all quoting commentary refs")
    p.add_argument("--force-update", action="store_true",
                   help="Recompute even if a relevance_score already exists for that commentary ref")
    p.add_argument("--limit", type=int, default=None,
                   help="Stop after discovering this many unique commentary refs (useful for testing)")
    p.add_argument("--dry-run", action="store_true",
                   help="Discover and count, but do not call generate_and_save_commentary_scoring()")
    p.add_argument("--sleep", type=float, default=0.0,
                   help="Optional sleep between scoring calls (seconds)")
    args = p.parse_args(argv)

    run_for_all_quoting_commentaries(
        force_update=args.force_update,
        limit=args.limit,
        dry_run=args.dry_run,
        sleep_sec=args.sleep,
    )
    return 0


if __name__ == "__main__":
    main()